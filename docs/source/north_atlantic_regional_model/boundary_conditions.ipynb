{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dc175c8-f744-4655-9037-b313c486c951",
   "metadata": {},
   "source": [
    "This notebook is used for the creation of model boundary conditions for the North Atlantic model. Just as for the initial condition, the boundary condition vector quantities need to rotated on the curvilinear model domain. \n",
    "\n",
    "First, import packages necessary for this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "836f57c0-6983-48ce-b8a0-31c5b04463a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the modules for computation, plotting, and reading files\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import netCDF4 as nc4\n",
    "import cmocean.cm as cm\n",
    "\n",
    "# import the necessary modules from eccoseas\n",
    "from eccoseas.ecco import io\n",
    "from eccoseas.ecco import grid as eeg\n",
    "from eccoseas.downscale import hFac\n",
    "from eccoseas.downscale import horizontal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea43d2c-8106-4b7e-9d71-dda71ff556e4",
   "metadata": {},
   "source": [
    "## Constructing the Boundary Conditions\n",
    "For this model, we will use a model state from the ECCO Version 5 state estimate. We will prepare the boundary condition fields in 7 steps:\n",
    "1. download the ECCO model output\n",
    "2. read the ECCO model grid\n",
    "3. read in the bathymetry for the regional model as well as its grid\n",
    "4. prepare the ECCO fields for interpolation\n",
    "5. interpolate the ECCO fields onto the regional model grid and store each as a binary file\n",
    "6. plot the interpolated fields to ensure they look as expected\n",
    "7. create an additional field for 1991"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5328af-a028-439b-a89a-4f39b72a9a65",
   "metadata": {},
   "source": [
    "### Step 1: Download the ECCO fields\n",
    "To begin, I downloaded the model fields generated by the ECCO Version 5 Alpha state estimate. These fields are available [HERE](https://ecco.jpl.nasa.gov/drive/files/Version5/Alpha/nctiles_monthly). In particular, we download the following list of files that contain the fields pertaining to time span of the model (1992 onward):\n",
    "\n",
    "| Variable | File Name |\n",
    "| -------- | --------- |\n",
    "|THETA|THETA/THETA_????.nc|\n",
    "|SALT|SALT/SALT_????.nc|\n",
    "|UVEL|UVELMASS/UVELMASS_????.nc|\n",
    "|VVEL|VVELMASS/VVELMASS_????.nc|\n",
    "|SIuice|SIuice/SIuice_????.nc|\n",
    "|SIvice|SIuice/SIvice_????.nc|\n",
    "|SIheff|SIheff/SIheff_????.nc|\n",
    "|SIhsnow|SIhsnow/SIhsnow_????.nc|\n",
    "|SIarea|SIarea/SIarea_????.nc|\n",
    "\n",
    "There are stored in the following directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34d9856c-ec0b-4f6e-9f9c-c18a73cd6858",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '../../../data/north_atlantic'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d170a9e7-8862-4e25-b732-1268f2c77c5a",
   "metadata": {},
   "source": [
    "### Step 2: Read in the ECCO grid\n",
    "To read in the ECCO fields, we will rely on the `io` module from the `eccoseas.ecco` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a925b6ec-93ab-429b-a830-d6591b15a327",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecco_XC_tiles = io.read_ecco_grid_tiles_from_nc(os.path.join(data_folder, 'GRID'), var_name='XC')\n",
    "ecco_YC_tiles = io.read_ecco_grid_tiles_from_nc(os.path.join(data_folder, 'GRID'), var_name='YC')\n",
    "ecco_AngleCS_tiles = io.read_ecco_grid_tiles_from_nc(os.path.join(data_folder, 'GRID'), var_name='AngleCS')\n",
    "ecco_AngleSN_tiles = io.read_ecco_grid_tiles_from_nc(os.path.join(data_folder, 'GRID'), var_name='AngleSN')\n",
    "ecco_hFacC_tiles = io.read_ecco_grid_tiles_from_nc(os.path.join(data_folder, 'GRID'), var_name='hFacC')\n",
    "ecco_hFacW_tiles = io.read_ecco_grid_tiles_from_nc(os.path.join(data_folder, 'GRID'), var_name='hFacW')\n",
    "ecco_hFacS_tiles = io.read_ecco_grid_tiles_from_nc(os.path.join(data_folder, 'GRID'), var_name='hFacS')\n",
    "ecco_RF_tiles = io.read_ecco_grid_tiles_from_nc(os.path.join(data_folder, 'GRID'), var_name='RF')\n",
    "ecco_DRF_tiles = io.read_ecco_grid_tiles_from_nc(os.path.join(data_folder, 'GRID'), var_name='DRF')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcf96ac-d0e5-4e53-884f-16e0fec32152",
   "metadata": {},
   "source": [
    "Note that in the previous notebook, we have already identified tiles 3, 7, and 11 as those pertaining to the regional domain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a135ac-a5bb-4766-83b5-60039dcc0c56",
   "metadata": {},
   "source": [
    "### Step 3: Read in the Model Grid and Generate a Mask\n",
    "Here, I will recreate the grid I will use in my model and read in the bathymetry file (see previous notebooks for details):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fe70cd2-1e3a-4045-8fc7-cd88e9777859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the input directory (see previous notebook for details)\n",
    "input_dir = '../../../configurations/north_atlantic/input'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f48b8cc3-eb40-40c3-b61e-1359d986109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the grids that will be used in the model\n",
    "ds = nc4.Dataset(os.path.join(input_dir,'north_atlantic_grid.nc'))\n",
    "XC = ds.variables['XC'][:,:]\n",
    "YC = ds.variables['YC'][:,:]\n",
    "bathy = -1*ds.variables['Depth'][:,:]\n",
    "AngleCS = ds.variables['AngleCS'][:,:]\n",
    "AngleSN = ds.variables['AngleSN'][:,:]\n",
    "hFacC = ds.variables['HFacC'][:,:]\n",
    "hFacS = ds.variables['HFacS'][:,:]\n",
    "hFacW = ds.variables['HFacW'][:,:]\n",
    "delR = ds.variables['drF'][:]\n",
    "ds.close()\n",
    "\n",
    "# remove the extra row and col from hFacS and hFacW\n",
    "hFacS = hFacS[:,:-1,:]\n",
    "hFacW = hFacW[:,:,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb82b3d-ffa2-4312-916f-3325a0089c6b",
   "metadata": {},
   "source": [
    "As in the initial condition notebook, we will make masks by setting all of the non-zero `hFac` points to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1dcfe0a-3641-43d7-99aa-88a48310eeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the masks\n",
    "maskC = np.copy(hFacC)\n",
    "maskC[maskC>0] = 1\n",
    "\n",
    "maskS = np.copy(hFacS)\n",
    "maskS[maskS>0] = 1\n",
    "\n",
    "maskW = np.copy(hFacW)\n",
    "maskW[maskW>0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37e0e64-13eb-4122-ae3c-0fead095fc9b",
   "metadata": {},
   "source": [
    "### Step 4: Prepare the grids for interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b332346e-acea-4d60-9494-8d850824b8f4",
   "metadata": {},
   "source": [
    "Next, we read in points from just the tiles overlapping out domain to use in interpolation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfd5f5ec-1a41-4da6-81aa-9d121dfa023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the tile list\n",
    "tile_list = [3,7,11]\n",
    "\n",
    "# determine the number of points in each set\n",
    "total_points = 0\n",
    "for tile_number in tile_list:\n",
    "    total_points += np.size(ecco_XC_tiles[tile_number])\n",
    "\n",
    "# make empty arrays to fill in\n",
    "ecco_XC_points = np.zeros((total_points, ))\n",
    "ecco_YC_points = np.zeros((total_points, ))\n",
    "ecco_AngleCS_points = np.zeros((total_points, ))\n",
    "ecco_AngleSN_points = np.zeros((total_points, ))\n",
    "ecco_maskC_points = np.zeros((np.size(ecco_RF_tiles[1]) , total_points))\n",
    "ecco_maskW_points = np.zeros((np.size(ecco_RF_tiles[1]) , total_points))\n",
    "ecco_maskS_points = np.zeros((np.size(ecco_RF_tiles[1]) , total_points))\n",
    "ecco_hFacW_points = np.zeros((np.size(ecco_RF_tiles[1]) , total_points))\n",
    "ecco_hFacS_points = np.zeros((np.size(ecco_RF_tiles[1]) , total_points))\n",
    "\n",
    "# loop through the tiles and fill in the XC, YC, and mask points for interpolation\n",
    "points_counted = 0\n",
    "for tile_number in tile_list:\n",
    "    tile_N = np.size(ecco_XC_tiles[tile_number])\n",
    "    \n",
    "    ecco_XC_points[points_counted:points_counted+tile_N] = ecco_XC_tiles[tile_number].ravel()\n",
    "    ecco_YC_points[points_counted:points_counted+tile_N] = ecco_YC_tiles[tile_number].ravel()\n",
    "\n",
    "    ecco_AngleCS_points[points_counted:points_counted+tile_N] = ecco_AngleCS_tiles[tile_number].ravel()\n",
    "    ecco_AngleSN_points[points_counted:points_counted+tile_N] = ecco_AngleSN_tiles[tile_number].ravel()\n",
    "    \n",
    "    for k in range(np.size(ecco_RF_tiles[tile_number])):\n",
    "        level_hFacC = ecco_hFacC_tiles[tile_number][k, :, :]\n",
    "        if tile_number<7:\n",
    "            level_hFacW = ecco_hFacW_tiles[tile_number][k, :, :]\n",
    "            level_hFacS = ecco_hFacS_tiles[tile_number][k, :, :]\n",
    "        else:\n",
    "            level_hFacS = ecco_hFacW_tiles[tile_number][k, :, :] # these are switched due to the \n",
    "            level_hFacW = ecco_hFacS_tiles[tile_number][k, :, :] # assumptions about velocity - see note below\n",
    "        ecco_hFacW_points[k, points_counted:points_counted+tile_N] = level_hFacW.ravel()\n",
    "        ecco_hFacS_points[k, points_counted:points_counted+tile_N] = level_hFacS.ravel()\n",
    "        level_maskC = np.copy(level_hFacC)\n",
    "        level_maskC[level_maskC>0] = 1\n",
    "        level_maskW = np.copy(level_hFacW)\n",
    "        level_maskW[level_maskW>0] = 1\n",
    "        level_maskS = np.copy(level_hFacS)\n",
    "        level_maskS[level_maskS>0] = 1\n",
    "        ecco_maskC_points[k, points_counted:points_counted+tile_N] = level_maskC.ravel()\n",
    "        ecco_maskW_points[k, points_counted:points_counted+tile_N] = level_maskW.ravel()\n",
    "        ecco_maskS_points[k, points_counted:points_counted+tile_N] = level_maskS.ravel()\n",
    "    \n",
    "    points_counted += tile_N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4462677-8079-45e5-9faf-d39452350218",
   "metadata": {},
   "source": [
    "Next, we'll read in the real data fields and apply the modifications. First, create a dictionary to store the file names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dbb96e5-bef6-4307-a5b3-f4441a930f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_file_dict(year):\n",
    "    file_prefix_dict = {'THETA':'THETA_'+str(year)+'.nc',\n",
    "                        'SALT':'SALT_'+str(year)+'.nc',\n",
    "                        'UVEL':'UVELMASS_'+str(year)+'.nc',\n",
    "                        'VVEL':'VVELMASS_'+str(year)+'.nc'}\n",
    "    variable_names = list(file_prefix_dict.keys())\n",
    "    return(variable_names, file_prefix_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf5206c-6f45-431e-9988-a1b007ce954e",
   "metadata": {},
   "source": [
    "Similarly, create a function to read in the variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6963b363-9245-4f9b-9f40-2b7318286460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_init_grids(year, variable_names, file_prefix_dict):\n",
    "    # make a list to hold all of the ECCO grids\n",
    "    init_grids = []\n",
    "    timesteps = 12\n",
    "    \n",
    "    # loop through each variable to read in the grid\n",
    "    for variable_name in variable_names:\n",
    "    \n",
    "        print('  - Reading in the data for '+str(variable_name)+' in year '+str(year))\n",
    "        \n",
    "        if variable_name == 'ETAN' or variable_name in ['SIarea','SIheff','SIhsnow']:\n",
    "            ds = nc4.Dataset(os.path.join(data_folder,variable_name,file_prefix_dict[variable_name]))\n",
    "            grid = ds.variables[variable_name][:,:,:,:]\n",
    "            ds.close()\n",
    "        elif 'VEL' in variable_name:\n",
    "            ds = nc4.Dataset(os.path.join(data_folder,'UVELMASS','UVELMASS_1992.nc'))\n",
    "            u_grid = ds.variables['UVELMASS'][:,:,:,:,:]\n",
    "            ds.close()\n",
    "            ds = nc4.Dataset(os.path.join(data_folder,'VVELMASS','VVELMASS_1992.nc'))\n",
    "            v_grid = ds.variables['VVELMASS'][:,:,:,:,:]\n",
    "            ds.close()\n",
    "        elif 'ice' in variable_name:\n",
    "            ds = nc4.Dataset(os.path.join(data_folder,'SIuice','SIuice_1992.nc'))\n",
    "            u_grid = ds.variables['SIuice'][:,:,:,:]\n",
    "            ds.close()\n",
    "            ds = nc4.Dataset(os.path.join(data_folder,'SIvice','SIvice_1992.nc'))\n",
    "            v_grid = ds.variables['SIvice'][:,:,:,:]\n",
    "            ds.close()\n",
    "        else:\n",
    "            ds = nc4.Dataset(os.path.join(data_folder,variable_name,file_prefix_dict[variable_name]))\n",
    "            grid = ds.variables[variable_name][:,:,:,:,:]\n",
    "            ds.close()\n",
    "\n",
    "    \n",
    "        # rotate grids, if needed\n",
    "        if 'VEL' in variable_name:\n",
    "            grid = np.zeros_like(u_grid)\n",
    "            for timestep in range(timesteps):\n",
    "                for tile_number in tile_list:\n",
    "                    zonal_grid, meridional_grid = eeg.rotate_ecco_vel_grids_to_natural_grids(u_grid[timestep,:,tile_number-1,:,:], v_grid[timestep,:,tile_number-1,:,:],\n",
    "                                                                                         ecco_AngleCS_tiles[tile_number], ecco_AngleSN_tiles[tile_number])\n",
    "                    if variable_name=='UVEL':\n",
    "                        grid[timestep,:,tile_number-1,:,:] = zonal_grid\n",
    "                    if variable_name=='VVEL':\n",
    "                        grid[timestep,:,tile_number-1,:,:] = meridional_grid\n",
    "        if 'ice' in variable_name:\n",
    "            grid = np.zeros_like(u_grid)\n",
    "            for timestep in range(timesteps):\n",
    "                for tile_number in tile_list:\n",
    "                    zonal_grid, meridional_grid = eeg.rotate_ecco_vel_grids_to_natural_grids(u_grid[timestep,tile_number-1,:,:], v_grid[timestep,tile_number-1,:,:],\n",
    "                                                                                         ecco_AngleCS_tiles[tile_number], ecco_AngleSN_tiles[tile_number], has_depth=False)\n",
    "                    if variable_name=='SIuice':\n",
    "                        grid[timestep,tile_number-1,:,:] = zonal_grid\n",
    "                    if variable_name=='SIvice':\n",
    "                        grid[timestep,tile_number-1,:,:] = meridional_grid\n",
    "    \n",
    "        # create a grid of zeros to fill in\n",
    "        N = np.shape(grid)[-1]*np.shape(grid)[-2]\n",
    "        if variable_name == 'ETAN'  or variable_name in ['SIarea','SIheff','SIhsnow','SIuice','SIvice']:\n",
    "            init_grid = np.zeros((timesteps, 1, N*len(tile_list)))\n",
    "        else:\n",
    "            init_grid = np.zeros((timesteps, np.size(ecco_RF_tiles[1]), N*len(tile_list)))\n",
    "\n",
    "        # loop through the tiles\n",
    "        points_counted = 0\n",
    "        for tile_number in tile_list:\n",
    "            if variable_name in ['ETAN','SIarea','SIheff','SIhsnow','SIuice','SIvice']:\n",
    "                for timestep in timesteps:\n",
    "                    init_grid[timestep, 0, points_counted:points_counted+N] = \\\n",
    "                         grid[timestep, tile_number-1, :, :].ravel()\n",
    "            else:\n",
    "                for timestep in range(timesteps):\n",
    "                    for k in range(np.size(ecco_RF_tiles[1])):\n",
    "                        init_grid[timestep, k, points_counted:points_counted+N] = \\\n",
    "                             grid[timestep, k, tile_number-1, :, :].ravel()\n",
    "            points_counted += N\n",
    "    \n",
    "        # apply some corrections to convert UVELMASS and VVELMASS to UVEL and VVEL\n",
    "        if variable_name == 'UVEL':\n",
    "            for timestep in range(timesteps):\n",
    "                for k in range(np.size(ecco_RF_tiles[1])):\n",
    "                    non_zero_indices = ecco_hFacW_points[k,:]!=0\n",
    "                    init_grid[timestep, k,non_zero_indices] = init_grid[timestep, k,non_zero_indices]/(ecco_hFacW_points[k,non_zero_indices])\n",
    "        if variable_name == 'VVEL':\n",
    "            for timestep in range(timesteps):\n",
    "                for k in range(np.size(ecco_RF_tiles[1])):\n",
    "                    non_zero_indices = ecco_hFacS_points[k,:]!=0\n",
    "                    init_grid[timestep, k,non_zero_indices] = init_grid[timestep, k,non_zero_indices]/(ecco_hFacS_points[k,non_zero_indices])\n",
    "        \n",
    "        init_grids.append(init_grid)\n",
    "    \n",
    "    return(init_grids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e32043-a3a3-49df-a724-de2be9f98708",
   "metadata": {},
   "source": [
    "### Step 5: Interpolate the Fields onto the Model Grid\n",
    "Next, we will interpolate the ECCO external fields I read in onto the regional model domain. We will use the `horizontal` module from the `eccoseas` package to accomplish this interpolation.\n",
    "\n",
    "First, define which boundaries we will need (all of them in this case):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6c081d0-77ac-4aba-8af7-baeb749a9a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the boundary list for the model\n",
    "boundary_list = ['west','south','north','east']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2595d28-7bb5-4c4f-83ef-2cf83147d401",
   "metadata": {},
   "source": [
    "Then, proceed with the interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c1028da-5a5b-4662-b772-73dadd97bd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'obcs' not in os.listdir(input_dir):\n",
    "    os.mkdir(os.path.join(input_dir,'obcs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0aae164-a3f8-470b-a973-7f7ddffdcef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in the data for THETA in year 1992\n",
      "Reading in the data for SALT in year 1992\n",
      "Reading in the data for UVEL in year 1992\n",
      "Reading in the data for VVEL in year 1992\n",
      "Working on the west boundary\n",
      "        - Interpolating the THETA grid\n",
      "        - Interpolating the SALT grid\n",
      "        - Interpolating the UVEL grid\n",
      "        - Interpolating the VVEL grid\n",
      "Working on the south boundary\n",
      "        - Interpolating the THETA grid\n",
      "        - Interpolating the SALT grid\n",
      "        - Interpolating the UVEL grid\n",
      "        - Interpolating the VVEL grid\n",
      "Working on the north boundary\n",
      "        - Interpolating the THETA grid\n",
      "        - Interpolating the SALT grid\n",
      "        - Interpolating the UVEL grid\n",
      "        - Interpolating the VVEL grid\n",
      "Working on the east boundary\n",
      "        - Interpolating the THETA grid\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(output_file):\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(timesteps):\n\u001b[0;32m---> 56\u001b[0m         interpolated_grid \u001b[38;5;241m=\u001b[39m \u001b[43mhorizontal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownscale_3D_points\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mecco_XC_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mecco_YC_points\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43minit_grid\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mecco_mask_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mboundary_XC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboundary_YC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboundary_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(delR)):\n\u001b[1;32m     60\u001b[0m             output_grid[t,k,:] \u001b[38;5;241m=\u001b[39m interpolated_grid[k,:,:]\u001b[38;5;241m.\u001b[39mravel()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mitgcm/lib/python3.10/site-packages/eccoseas/downscale/horizontal.py:662\u001b[0m, in \u001b[0;36mdownscale_3D_points\u001b[0;34m(L0_points, L0_var, L0_wet_grid, XC_subset, YC_subset, L1_wet_grid, mean_vertical_difference, fill_downward, printing, remove_zeros, testing)\u001b[0m\n\u001b[1;32m    659\u001b[0m     L0_values \u001b[38;5;241m=\u001b[39m L0_values[L0_values \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(L0_points)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m--> 662\u001b[0m     grid \u001b[38;5;241m=\u001b[39m \u001b[43mgriddata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL0_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mL0_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mXC_subset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYC_subset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlinear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    663\u001b[0m     \u001b[38;5;66;03m# grid = grid[:, :, 0]\u001b[39;00m\n\u001b[1;32m    664\u001b[0m     \u001b[38;5;66;03m# grid_nearest = griddata(L0_points, L0_values, (XC_subset, YC_subset), method='nearest', fill_value=0)\u001b[39;00m\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;66;03m# grid_nearest[:,:,0]\u001b[39;00m\n\u001b[1;32m    666\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(grid\u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mitgcm/lib/python3.10/site-packages/scipy/interpolate/_ndgriddata.py:323\u001b[0m, in \u001b[0;36mgriddata\u001b[0;34m(points, values, xi, method, fill_value, rescale)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ip(xi)\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 323\u001b[0m     ip \u001b[38;5;241m=\u001b[39m \u001b[43mLinearNDInterpolator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mrescale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrescale\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ip(xi)\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcubic\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m ndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m_interpnd.pyx:302\u001b[0m, in \u001b[0;36mscipy.interpolate._interpnd.LinearNDInterpolator.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_interpnd.pyx:93\u001b[0m, in \u001b[0;36mscipy.interpolate._interpnd.NDInterpolatorBase.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_interpnd.pyx:306\u001b[0m, in \u001b[0;36mscipy.interpolate._interpnd.LinearNDInterpolator._calculate_triangulation\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_qhull.pyx:1887\u001b[0m, in \u001b[0;36mscipy.spatial._qhull.Delaunay.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_qhull.pyx:1596\u001b[0m, in \u001b[0;36mscipy.spatial._qhull._QhullUser.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_qhull.pyx:1905\u001b[0m, in \u001b[0;36mscipy.spatial._qhull.Delaunay._update\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_qhull.pyx:1625\u001b[0m, in \u001b[0;36mscipy.spatial._qhull._QhullUser._update\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mitgcm/lib/python3.10/site-packages/numpy/core/_methods.py:43\u001b[0m, in \u001b[0;36m_amin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_amax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     40\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_maximum(a, axis, \u001b[38;5;28;01mNone\u001b[39;00m, out, keepdims, initial, where)\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_amin\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     44\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_minimum(a, axis, \u001b[38;5;28;01mNone\u001b[39;00m, out, keepdims, initial, where)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "timesteps = 12\n",
    "years = np.arange(1992,1993).tolist() # showing 1992 for now, but this should be extended to 2017 for the full model run\n",
    "\n",
    "for year in years:\n",
    "\n",
    "    print('Reading in the data for year '+str(year))\n",
    "    variable_names, file_prefix_dict = make_file_dict(year)\n",
    "    init_grids = read_init_grids(year, variable_names, file_prefix_dict)\n",
    "\n",
    "    print('Creating the boundary conditions')\n",
    "    # loop through each boundary\n",
    "    for boundary in boundary_list:\n",
    "        \n",
    "        print('  - Working on the '+boundary+' boundary')\n",
    "\n",
    "        # loop through each variable and corresponding ECCO grid\n",
    "        for variable_name, init_grid in zip(variable_names, init_grids):\n",
    "\n",
    "            if variable_name == 'UVEL':\n",
    "                mask = maskW\n",
    "                ecco_mask_points = ecco_maskW_points\n",
    "            elif variable_name == 'VVEL':\n",
    "                mask = maskS\n",
    "                ecco_mask_points = ecco_maskS_points\n",
    "            else:\n",
    "                mask = maskC\n",
    "                ecco_mask_points = ecco_maskC_points\n",
    "        \n",
    "            if boundary == 'west':\n",
    "                boundary_XC = XC[:,:1]\n",
    "                boundary_YC = YC[:,:1]\n",
    "                boundary_mask = mask[:,:,:1]\n",
    "            elif boundary == 'east':\n",
    "                boundary_XC = XC[:,-1:]\n",
    "                boundary_YC = YC[:,-1:]\n",
    "                boundary_mask = mask[:,:,-1:]\n",
    "            elif boundary == 'north':\n",
    "                boundary_XC = XC[-1:,:]\n",
    "                boundary_YC = YC[-1:,:]\n",
    "                boundary_mask = mask[:,-1:,:]\n",
    "            elif boundary == 'south':\n",
    "                boundary_XC = XC[:1,:]\n",
    "                boundary_YC = YC[:1,:]\n",
    "                boundary_mask = mask[:,:1,:]\n",
    "            else:\n",
    "                raise ValueError('Boundary '+boundary+' not recognized')\n",
    "\n",
    "            output_grid = np.zeros((timesteps, np.size(delR), np.size(boundary_XC)))\n",
    "\n",
    "            # print a message to keep track of which variable we are working on\n",
    "            print('        - Interpolating the '+variable_name+' grid')\n",
    "            output_file = os.path.join(input_dir,'obcs',variable_name+'_'+boundary+'_'+str(year))\n",
    "            \n",
    "            # only run the routine if the file hasn't been made yet\n",
    "            if not os.path.exists(output_file):\n",
    "    \n",
    "                for t in range(timesteps):\n",
    "                    interpolated_grid = horizontal.downscale_3D_points(np.column_stack([ecco_XC_points, ecco_YC_points]),\n",
    "                                                                       init_grid[t,:,:], ecco_mask_points, \n",
    "                                                                       boundary_XC, boundary_YC, boundary_mask)\n",
    "                    for k in range(len(delR)):\n",
    "                        output_grid[t,k,:] = interpolated_grid[k,:,:].ravel()\n",
    "    \n",
    "                # output the interpolated grid\n",
    "                output_grid.ravel('C').astype('>f4').tofile(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe30ee2-7b83-498d-813c-9b9ea152ed6f",
   "metadata": {},
   "source": [
    "### Step 6: Plotting the Boundary Fields\n",
    "Now that the fields have been generated, plot them to ensure they look as expected. First, generate some metadata for each one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ac447d-91d1-4a85-b4c3-12529580db54",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dict = {'THETA':[6, 18, 'turbo', 'm'],\n",
    "            'SALT':[32, 35, 'viridis', 'm'],\n",
    "            'UVEL':[-0.1, 0.1, 'seismic', 'm'],\n",
    "            'VVEL':[-0.1, 0.1, 'seismic', 'm']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c60e704-57ae-4d35-aca8-2dbc8ad5f84a",
   "metadata": {},
   "source": [
    "Then, create all of the subplots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd252056-d8e7-4cce-a50d-43e20b50c301",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "plot_year = 1992\n",
    "\n",
    "plot_counter = 0\n",
    "for i in range(len(variable_names)):\n",
    "    variable_name = variable_names[i]\n",
    "    \n",
    "    for boundary in boundary_list:\n",
    "        \n",
    "        boundary_grid = np.fromfile(os.path.join(input_dir,'obcs',variable_name+'_'+boundary+'_'+str(plot_year)),'>f4')\n",
    "    \n",
    "        if boundary in ['west','east']:\n",
    "            boundary_grid = boundary_grid.reshape((timesteps, np.shape(delR)[0],np.shape(XC)[0]))\n",
    "            boundary_grid = boundary_grid[0, :, :] # choose just the first timestep for plotting\n",
    "            if boundary=='west':\n",
    "                x = YC[:,1]\n",
    "            if boundary=='east':\n",
    "                x = YC[:,-1]\n",
    "        else:\n",
    "            boundary_grid = boundary_grid.reshape((timesteps, np.shape(delR)[0],np.shape(XC)[1]))\n",
    "            boundary_grid = boundary_grid[0, :, :] # choose just the first timestep for plotting\n",
    "            if boundary=='north':\n",
    "                x = XC[-1,:]\n",
    "            if boundary=='south':\n",
    "                x = XC[1,:]\n",
    "\n",
    "        plot_counter += 1\n",
    "        plt.subplot(len(variable_names),len(boundary_list),plot_counter)\n",
    "        C = plt.pcolormesh(x, Z, boundary_grid,\n",
    "                           vmin=meta_dict[variable_names[i]][0],\n",
    "                           vmax=meta_dict[variable_names[i]][1],\n",
    "                           cmap=meta_dict[variable_names[i]][2])\n",
    "        plt.colorbar(C,fraction=0.26)\n",
    "        plt.gca().invert_yaxis()\n",
    "    \n",
    "        if plot_counter%3==1:\n",
    "            plt.ylabel(variable_name)\n",
    "        if plot_counter<4:\n",
    "            plt.title(boundary)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09ea7f2-2254-47f8-989b-04990088b89a",
   "metadata": {},
   "source": [
    "Looks good! Now, with the initial conditions, external forcing conditions, and boundary conditions we are nearly ready to start testing the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2c2c18-d5f5-41c2-8c84-fd6120766912",
   "metadata": {},
   "source": [
    "### An additional field for 1991\n",
    "When the model is initiated in 1992, the regional model will interpolate between times to compute the boundary conditions. However, this will require one timestep from the end of 1991 - which we don't have. To initiate the model, we can copy over the boundary conditions from the start of 1992 to the end of 1991 for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5638894-50bd-4183-8c43-47e9f90f957b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(variable_names)):\n",
    "    variable_name = variable_names[i]\n",
    "    \n",
    "    for boundary in boundary_list:\n",
    "        print('Copying '+variable_name+' 1992 consitions for the '+boundary+' boundary in 1991')\n",
    "\n",
    "        boundary_grid = np.fromfile(os.path.join(input_dir,'obcs',variable_name+'_'+boundary+'_1992'),'>f4')\n",
    "    \n",
    "        if boundary in ['west','east']:\n",
    "            boundary_grid = boundary_grid.reshape((timesteps, np.shape(delR)[0],np.shape(XC)[0]))\n",
    "        else:\n",
    "            boundary_grid = boundary_grid.reshape((timesteps, np.shape(delR)[0],np.shape(XC)[1]))\n",
    "\n",
    "        boundary_grid_1991 = np.copy(boundary_grid)\n",
    "        for timestep in range(12):\n",
    "            boundary_grid_1991[timestep,:,:] = boundary_grid[0,:,:]\n",
    "\n",
    "        output_file = os.path.join(input_dir,'obcs',variable_name+'_'+boundary+'_'+str(1991))\n",
    "        boundary_grid_1991.ravel('C').astype('>f4').tofile(output_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mitgcm",
   "language": "python",
   "name": "mitgcm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
